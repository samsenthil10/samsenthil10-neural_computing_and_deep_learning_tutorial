{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quDlLWcAP31q"
   },
   "source": [
    "## MLP for Binary Classification\n",
    "\n",
    "In this lab, you will use the Ionosphere data binary (two-class) classification dataset to demonstrate an MLP for binary classification.\n",
    "\n",
    "This dataset involves predicting whether a structure is in the atmosphere or not given radar returns.\n",
    "\n",
    "The dataset will be downloaded automatically using Pandas, but you can learn more in the links below.\n",
    "\n",
    "[Ionosphere Dataset (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv)\n",
    "\n",
    "[Ionosphere Dataset Description (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.names)\n",
    "\n",
    "\n",
    "Your task for this is lab is to develop a Keras-based Multi-Layer Perceptron model for this data set. Remember the number of output layers is equal to the number of classes.\n",
    "\n",
    "Following we have provided some piece of code to you while you need to complete the rest of the code on your own.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6086ipzNP31q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sasen\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "# Your code to import read_csv class from pandas\n",
    "import pandas as pd\n",
    "# Your code to import train_test_split class from sklearn. Follow link https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7755rFn_iDRj"
   },
   "source": [
    "# Read the dataset from the path below. Store the data in a pandas dataframe named 'df'\n",
    "\n",
    "Link to API - https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "058u-qkXP31r"
   },
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
    "# Your code to read the csv from the above path.\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vG3n2OHrjQsG"
   },
   "source": [
    "See the sample dataset. Print few rows of the dataset. Use dataframe.head() method.\n",
    "\n",
    "Link to API:  https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jx3JTj4sfUIt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1        2        3        4        5        6        7        8   \\\n",
       "0   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "3   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "4   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "\n",
       "        9   ...       25       26       27       28       29       30  \\\n",
       "0  0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "1 -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "2  0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "3  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "4 -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "\n",
       "        31       32       33  34  \n",
       "0 -0.54487  0.18641 -0.45300   g  \n",
       "1 -0.06288 -0.13738 -0.02447   b  \n",
       "2 -0.24180  0.56045 -0.38238   g  \n",
       "3  1.00000 -0.32382  1.00000   b  \n",
       "4 -0.59573 -0.04608 -0.65697   g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to print first few rows of the dataset.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo8Siqyxfhj7"
   },
   "source": [
    "Print the basic info of the dataset. Use dataframe.info() from pandas library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "VgN9rYV_fiag"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 35 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       351 non-null    int64  \n",
      " 1   1       351 non-null    int64  \n",
      " 2   2       351 non-null    float64\n",
      " 3   3       351 non-null    float64\n",
      " 4   4       351 non-null    float64\n",
      " 5   5       351 non-null    float64\n",
      " 6   6       351 non-null    float64\n",
      " 7   7       351 non-null    float64\n",
      " 8   8       351 non-null    float64\n",
      " 9   9       351 non-null    float64\n",
      " 10  10      351 non-null    float64\n",
      " 11  11      351 non-null    float64\n",
      " 12  12      351 non-null    float64\n",
      " 13  13      351 non-null    float64\n",
      " 14  14      351 non-null    float64\n",
      " 15  15      351 non-null    float64\n",
      " 16  16      351 non-null    float64\n",
      " 17  17      351 non-null    float64\n",
      " 18  18      351 non-null    float64\n",
      " 19  19      351 non-null    float64\n",
      " 20  20      351 non-null    float64\n",
      " 21  21      351 non-null    float64\n",
      " 22  22      351 non-null    float64\n",
      " 23  23      351 non-null    float64\n",
      " 24  24      351 non-null    float64\n",
      " 25  25      351 non-null    float64\n",
      " 26  26      351 non-null    float64\n",
      " 27  27      351 non-null    float64\n",
      " 28  28      351 non-null    float64\n",
      " 29  29      351 non-null    float64\n",
      " 30  30      351 non-null    float64\n",
      " 31  31      351 non-null    float64\n",
      " 32  32      351 non-null    float64\n",
      " 33  33      351 non-null    float64\n",
      " 34  34      351 non-null    object \n",
      "dtypes: float64(32), int64(2), object(1)\n",
      "memory usage: 96.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Your code to print information about the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AX_YFAb4kdl4"
   },
   "source": [
    "Print the shape of the dataframe. Select suitable API call from the pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rlfCOssvf44O"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to print the shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aekdoY2zkxU4"
   },
   "source": [
    "# Separate the input and output from the dataframe. Input is all columns besides last column. Output is the last column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "_5bh8al2P31s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
       "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
       "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
       "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
       "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
       "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
       "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
       "       'b', 'g', 'b', 'g', 'b', 'g', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
       "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
       "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
       "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
       "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
       "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
       "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
       "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
       "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
       "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
       "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
       "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
       "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
       "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
       "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
       "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
       "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
       "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
       "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
       "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.values[:, :-1]\n",
    "# Your code to get y - Hint y = df.values[:, some parameters]\n",
    "y = df.values[:,-1]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7y3GhJDloqk"
   },
   "source": [
    "We have converted everthing in X to 'float' and the letters in column y to the numbers in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "qVtPf2F9lg17"
   },
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZ_aY4H3l9bI"
   },
   "source": [
    "Printing the genral information of the X and y in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "BWBOMrBigew9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      "[[ 1.       0.       0.99539 ... -0.54487  0.18641 -0.453  ]\n",
      " [ 1.       0.       1.      ... -0.06288 -0.13738 -0.02447]\n",
      " [ 1.       0.       1.      ... -0.2418   0.56045 -0.38238]\n",
      " ...\n",
      " [ 1.       0.       0.94701 ...  0.00442  0.92697 -0.00577]\n",
      " [ 1.       0.       0.90608 ... -0.03757  0.87403 -0.16243]\n",
      " [ 1.       0.       0.8471  ... -0.06678  0.85764 -0.06151]]\n",
      "y: \n",
      "[1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "X Shape:  (351, 34)\n",
      "Y Shape:  (351,)\n"
     ]
    }
   ],
   "source": [
    "# Your code to print X\n",
    "print(\"X: \" , X , sep=\"\\n\")\n",
    "# Your code to print y\n",
    "print(\"y: \" , y , sep=\"\\n\")\n",
    "# your code to print shape of X. Remember X is a numpy array\n",
    "print(\"X Shape: \", X.shape)\n",
    "# your code to print shape of y. Remember y is a numpy array\n",
    "print(\"Y Shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9ltrLLqmkgW"
   },
   "source": [
    "* Separate X and y into training and test set with a ratio of your choice.\n",
    "* Print the shapes of the resulting arrays.\n",
    "* Get the number of features from X_train. Remember the number of features are the number of inputs.\n",
    "\n",
    "Use sklearn train_test_split class.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "-CjFJcAMP31s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape:  (245, 34)\n",
      "X_test Shape:  (106, 34)\n",
      "y_train Shape:  (245,)\n",
      "y_test Shape:  (106,)\n"
     ]
    }
   ],
   "source": [
    "# Your code to separate the data into trauning and test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Your code to print shape of X_train\n",
    "print(\"X_train Shape: \", X_train.shape)\n",
    "# Your code to print shape of X_test\n",
    "print(\"X_test Shape: \", X_test.shape)\n",
    "# Your code to print shape of y_train\n",
    "print(\"y_train Shape: \", y_train.shape)\n",
    "# Your code to print shape of X_test\n",
    "print(\"y_test Shape: \", y_test.shape)\n",
    "\n",
    "\n",
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQdqYXJ9pqzC"
   },
   "source": [
    "# Creating a Multi-layer Perceptron using Keras.\n",
    "We have added first and last layers. Create the hidden layers of your choise.\n",
    "You can chose any number of hidden layers and activation function of your chose\n",
    "https://keras.io/api/layers/core_layers/dense/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "hhTE3u-_P31t"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "#\n",
    "# Add as many layers with activation functions of your choice\n",
    "#\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NtBU922rH67"
   },
   "source": [
    "In the next cell, we trained the above neural network model and tested its accuracy. As this concept has still not benn covered in the class, just run the code to check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "krgB1SuRP31t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "8/8 [==============================] - 2s 5ms/step - loss: 0.6979 - accuracy: 0.6898\n",
      "Epoch 2/150\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.6898\n",
      "Epoch 3/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6521 - accuracy: 0.6980\n",
      "Epoch 4/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.6939\n",
      "Epoch 5/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.6980\n",
      "Epoch 6/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.7061\n",
      "Epoch 7/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.7102\n",
      "Epoch 8/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7224\n",
      "Epoch 9/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7306\n",
      "Epoch 10/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7347\n",
      "Epoch 11/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7510\n",
      "Epoch 12/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7551\n",
      "Epoch 13/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7714\n",
      "Epoch 14/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7796\n",
      "Epoch 15/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7837\n",
      "Epoch 16/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7837\n",
      "Epoch 17/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7918\n",
      "Epoch 18/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8000\n",
      "Epoch 19/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.8204\n",
      "Epoch 20/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8286\n",
      "Epoch 21/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.8327\n",
      "Epoch 22/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8408\n",
      "Epoch 23/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8449\n",
      "Epoch 24/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8449\n",
      "Epoch 25/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8449\n",
      "Epoch 26/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8571\n",
      "Epoch 27/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8653\n",
      "Epoch 28/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8735\n",
      "Epoch 29/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8735\n",
      "Epoch 30/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8735\n",
      "Epoch 31/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.8735\n",
      "Epoch 32/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8816\n",
      "Epoch 33/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8816\n",
      "Epoch 34/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8816\n",
      "Epoch 35/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8857\n",
      "Epoch 36/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8898\n",
      "Epoch 37/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8898\n",
      "Epoch 38/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8898\n",
      "Epoch 39/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8898\n",
      "Epoch 40/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8898\n",
      "Epoch 41/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8980\n",
      "Epoch 42/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8980\n",
      "Epoch 43/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8980\n",
      "Epoch 44/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8980\n",
      "Epoch 45/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8980\n",
      "Epoch 46/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8980\n",
      "Epoch 47/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2973 - accuracy: 0.8980\n",
      "Epoch 48/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.9020\n",
      "Epoch 49/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.9061\n",
      "Epoch 50/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.9061\n",
      "Epoch 51/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2856 - accuracy: 0.9020\n",
      "Epoch 52/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.9020\n",
      "Epoch 53/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2790 - accuracy: 0.9020\n",
      "Epoch 54/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2761 - accuracy: 0.9020\n",
      "Epoch 55/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.9061\n",
      "Epoch 56/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.9061\n",
      "Epoch 57/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.9061\n",
      "Epoch 58/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.9061\n",
      "Epoch 59/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2639 - accuracy: 0.9061\n",
      "Epoch 60/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.9061\n",
      "Epoch 61/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.9061\n",
      "Epoch 62/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.9102\n",
      "Epoch 63/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2541 - accuracy: 0.9061\n",
      "Epoch 64/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2520 - accuracy: 0.9102\n",
      "Epoch 65/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2499 - accuracy: 0.9102\n",
      "Epoch 66/150\n",
      "8/8 [==============================] - 0s 976us/step - loss: 0.2484 - accuracy: 0.9061\n",
      "Epoch 67/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.9061\n",
      "Epoch 68/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.9102\n",
      "Epoch 69/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2419 - accuracy: 0.9143\n",
      "Epoch 70/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.9102\n",
      "Epoch 71/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.9184\n",
      "Epoch 72/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2361 - accuracy: 0.9184\n",
      "Epoch 73/150\n",
      "8/8 [==============================] - 0s 944us/step - loss: 0.2343 - accuracy: 0.9184\n",
      "Epoch 74/150\n",
      "8/8 [==============================] - 0s 987us/step - loss: 0.2327 - accuracy: 0.9184\n",
      "Epoch 75/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9184\n",
      "Epoch 76/150\n",
      "8/8 [==============================] - 0s 994us/step - loss: 0.2292 - accuracy: 0.9184\n",
      "Epoch 77/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2274 - accuracy: 0.9184\n",
      "Epoch 78/150\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2259 - accuracy: 0.9224\n",
      "Epoch 79/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9224\n",
      "Epoch 80/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9224\n",
      "Epoch 81/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2210 - accuracy: 0.9224\n",
      "Epoch 82/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2194 - accuracy: 0.9184\n",
      "Epoch 83/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2180 - accuracy: 0.9224\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2169 - accuracy: 0.9224\n",
      "Epoch 85/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2150 - accuracy: 0.9265\n",
      "Epoch 86/150\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2139 - accuracy: 0.9265\n",
      "Epoch 87/150\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2121 - accuracy: 0.9265\n",
      "Epoch 88/150\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2109 - accuracy: 0.9224\n",
      "Epoch 89/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9224\n",
      "Epoch 90/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2084 - accuracy: 0.9224\n",
      "Epoch 91/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9306\n",
      "Epoch 92/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9306\n",
      "Epoch 93/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2041 - accuracy: 0.9306\n",
      "Epoch 94/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9306\n",
      "Epoch 95/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2018 - accuracy: 0.9306\n",
      "Epoch 96/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2004 - accuracy: 0.9347\n",
      "Epoch 97/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9347\n",
      "Epoch 98/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1980 - accuracy: 0.9347\n",
      "Epoch 99/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9347\n",
      "Epoch 100/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1955 - accuracy: 0.9347\n",
      "Epoch 101/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9347\n",
      "Epoch 102/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9347\n",
      "Epoch 103/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.9347\n",
      "Epoch 104/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9347\n",
      "Epoch 105/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9347\n",
      "Epoch 106/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9347\n",
      "Epoch 107/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9347\n",
      "Epoch 108/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9347\n",
      "Epoch 109/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.9347\n",
      "Epoch 110/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1842 - accuracy: 0.9347\n",
      "Epoch 111/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9388\n",
      "Epoch 112/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.9388\n",
      "Epoch 113/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1813 - accuracy: 0.9388\n",
      "Epoch 114/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1801 - accuracy: 0.9388\n",
      "Epoch 115/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9388\n",
      "Epoch 116/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9388\n",
      "Epoch 117/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9388\n",
      "Epoch 118/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.9388\n",
      "Epoch 119/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9388\n",
      "Epoch 120/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 0.9388\n",
      "Epoch 121/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 0.9388\n",
      "Epoch 122/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1725 - accuracy: 0.9388\n",
      "Epoch 123/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.9388\n",
      "Epoch 124/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9388\n",
      "Epoch 125/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.9388\n",
      "Epoch 126/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.9388\n",
      "Epoch 127/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.9388\n",
      "Epoch 128/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 0.9388\n",
      "Epoch 129/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1662 - accuracy: 0.9388\n",
      "Epoch 130/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9429\n",
      "Epoch 131/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1648 - accuracy: 0.9388\n",
      "Epoch 132/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.9388\n",
      "Epoch 133/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9388\n",
      "Epoch 134/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1621 - accuracy: 0.9388\n",
      "Epoch 135/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1614 - accuracy: 0.9388\n",
      "Epoch 136/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1606 - accuracy: 0.9388\n",
      "Epoch 137/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1597 - accuracy: 0.9429\n",
      "Epoch 138/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.9429\n",
      "Epoch 139/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1582 - accuracy: 0.9429\n",
      "Epoch 140/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1574 - accuracy: 0.9388\n",
      "Epoch 141/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1569 - accuracy: 0.9388\n",
      "Epoch 142/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9429\n",
      "Epoch 143/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1550 - accuracy: 0.9429\n",
      "Epoch 144/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9429\n",
      "Epoch 145/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9469\n",
      "Epoch 146/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9429\n",
      "Epoch 147/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9469\n",
      "Epoch 148/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1517 - accuracy: 0.9429\n",
      "Epoch 149/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1506 - accuracy: 0.9469\n",
      "Epoch 150/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.9469\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8868\n",
      "Test Accuracy: 0.887\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=1)\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ReYGy_jsCh0"
   },
   "source": [
    "** How much accuracy have you got? Compare the accuracy with your peers. **\n",
    "** Now, change your model and activation function to get the better accuracy as compared to your peers **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmeq5l1edZPg"
   },
   "source": [
    "## **Important:** Document in your lab logbook the accuracy of the improved model. Do not include any code or explanations in your lab logbook. Simply record the accuracy. For example, if the obtained accuracy is 0.98, then enter \"0.98\" in your lab logbook.\n",
    "\n",
    "## In addition to the accuracy, also document the output of the neural network as provided in Task 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFNL8fY2rd41"
   },
   "source": [
    "\n",
    "Next, we have provided the code to predict on an unknown value.\n",
    "We will cover these concepts later in the class. For now, just run the code to see the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXV7gQRAP31u",
    "outputId": "a5092aea-3cad-4009-de83-956caa73ecba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n",
      "Predicted: 0.950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasen\\AppData\\Local\\Temp\\ipykernel_1880\\3885243746.py:8: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('Predicted: %.3f' % yhat)\n"
     ]
    }
   ],
   "source": [
    "row = [1,0,0.99539,-0.05889,0.85243,0.02306,\n",
    "       0.83398,-0.37708,1,0.03760,0.85243,-0.17755,\n",
    "       0.59755,-0.44945,0.60536,-0.38223,0.84356,\n",
    "       -0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,\n",
    "       -0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,\n",
    "       -0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNFK4kV9P31u"
   },
   "source": [
    "### Try out the same model with Keras Functional models!\n",
    "Refer to [Keras](https://keras.io/) for more details and tutorials for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(128, activation='relu', input_shape=(n_features,)))\n",
    "model_1.add(Dense(128, activation='relu', input_shape=(n_features,)))\n",
    "model_1.add(Dense(128, activation='relu', input_shape=(n_features,)))\n",
    "model_1.add(Dense(128, activation='relu', input_shape=(n_features,)))\n",
    "model_1.add(Dense(128, activation='relu', input_shape=(n_features,)))\n",
    "model_1.add(Dense(128, activation='relu', input_shape=(n_features,)))\n",
    "model_1.add(Dense(1, activation='sigmoid', input_shape=(n_features,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "8/8 [==============================] - 2s 5ms/step - loss: 0.6402 - accuracy: 0.6490\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.8204\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2223 - accuracy: 0.9224\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1193 - accuracy: 0.9469\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9796\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9796\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9837\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9837\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9755\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9837\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.9918\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9878\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9959\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9959\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.9959\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9959\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9959\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9959\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9959\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.1670e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.0882e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.5957e-04 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8781e-04 - accuracy: 1.0000\n",
      "4/4 [==============================] - 1s 5ms/step - loss: 0.2160 - accuracy: 0.9528\n",
      "Test Accuracy: 0.953\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model_1.fit(X_train, y_train, epochs=30, batch_size=32, verbose=1)\n",
    "\n",
    "loss, acc = model_1.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "Accuracy = history_dict['accuracy']\n",
    "plt.figure(num = 1, figsize=(15,7))\n",
    "plt.plot(Accuracy, \"gx\", label = \"Training Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_211 (Dense)           (None, 128)               4480      \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70657 (276.00 KB)\n",
      "Trainable params: 70657 (276.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n",
      "Predicted: 0.950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasen\\AppData\\Local\\Temp\\ipykernel_1880\\3885243746.py:8: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('Predicted: %.3f' % yhat)\n"
     ]
    }
   ],
   "source": [
    "row = [1,0,0.99539,-0.05889,0.85243,0.02306,\n",
    "       0.83398,-0.37708,1,0.03760,0.85243,-0.17755,\n",
    "       0.59755,-0.44945,0.60536,-0.38223,0.84356,\n",
    "       -0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,\n",
    "       -0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,\n",
    "       -0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
